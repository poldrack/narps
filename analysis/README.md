### Code for NARPS data analysis

[![DOI](https://zenodo.org/badge/85984198.svg)](https://zenodo.org/badge/latestdoi/85984198) [![CircleCI](https://circleci.com/gh/poldrack/narps.svg?style=svg)](https://circleci.com/gh/poldrack/narps) [![Codacy Badge](https://api.codacy.com/project/badge/Grade/c35f17b180aa4b1e8cbd33b9b1473c3e)](https://www.codacy.com/app/poldrack/narps?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=poldrack/narps&amp;utm_campaign=Badge_Grade) [![Coverage Status](https://coveralls.io/repos/github/poldrack/narps/badge.svg?branch=master)](https://coveralls.io/github/poldrack/narps?branch=master)

#### Setup

In order to run this code, you must obtain the URL for the original data from Russ Poldrack - these data will be made publicly available upon publication of the paper.

The required data (all contained in the unzipped ```orig``` directory) are:

-   thresholded and unthresholded images for each team/hypothesis (teams excluded from the main analysis are included in the ```rejected``` directory)

-   Metadata files:
    -   ```analysis_pipelines_SW.xlsx``` (information about analysis pipelines)
    -   ```narps_neurovault_images_details.csv``` (information about images)
    -]  ```narps_results.xlsx``` (information about team decisions)

In addition, there is a set of template files (redistributed from the FSL distribution) contained in the ```templates``` directory:
    -   ```templates/MNI152_T1_2mm.nii.gz```
    -   ```templates/MNI152_T1_2mm_brain_mask.nii.gz```

#### Dockerized analysis pipeline

To run the full analysis pipeline using Docker, do the following:

-   Install the [Docker client](https://docs.docker.com/install/)
-   set the following environment variables:
    -   ```NARPS_BASEDIR```: location for the data and results
    -   ```DATA_URL```: URL for the data
-   clone the present repository and cd to the cloned directory
-   use the following command to run the full pipeline: ```make run-all```

This performs the following steps:

-   Preparation of the data for analysis(using narps.py)
-   Preparation of the metadata (using PrepareMetadata.py)
-   Analysis of the maps (using AnalyzeMaps.py)
-   Analysis of the decisions (using AnalyzeDecisions.Rmd)
-   Consensus analysis across teams (using ConsensusAnalysis.py)

The outputs can be found in the subdirectories of NARPS_BASEDIR:
-   ```maps``` - all of the intermediate maps generated by preprocessing
-   ```figures``` - figures generated by the analysis code
-   ```metadata``` - additional metadata files generated by the preparation code
-   ```cached``` - the cached narps structure 

This will use the latest version of the docker image from Dockerhub.  If you wish to build the Docker image locally, you should change the DOCKER_USERNAME variable in the Makefile to your own username, and then run ```make docker-build```.

#### Reproducibility

We have attempted to maximize the reproducibility of the analyses in this project as follows:

-   *Python/UNIX*: All software versions for UNIX and Python packages are pinned in the Dockerfile
-   *R*: R is tricky because it doesn't provide a straightforward way to specify versions of libraries.  We use a package called [checkpoint](https://cran.r-project.org/web/packages/checkpoint/vignettes/checkpoint.html), which downloads the versions of all necessary packages as of a specific date (which we have set to 2019-07-16).  The checkpoint packages analyzes R code in the project and downloads any libraries that are loaded by the code; unfortunately it doesn't read Rmd files, so we create a separate file called R_libraries.R that contains the imports needed to run the Rmd file, and which will be detected by checkpoint such that those libraries are loaded automatically.  This is generated automatically when the analysis is run, and can also be generated using ```make get-R-packages```.

### Local execution

Execution via Docker is recommended, but the analysis can also be run locally, using ```make run-all-local``` - this will require that you have all of the various requirements in place, which must be inferred from the Dockerfile.


